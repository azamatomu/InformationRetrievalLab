{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11087501_12057398_12234036_code.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "0rcVBd2D_VDc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Homework Assignment - Part B"
      ]
    },
    {
      "metadata": {
        "id": "QcOflOk-_tOU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "id": "kKrj2nFE_vnc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import itertools\n",
        "import math\n",
        "import csv\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy import stats\n",
        "from scipy.stats import norm, ttest_ind\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xE5YipkurYT4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Google Drive and the Yandex clicklog file"
      ]
    },
    {
      "metadata": {
        "id": "LDJKcQ_Orj4g",
        "colab_type": "code",
        "outputId": "8ec07c36-72a2-4072-8ca4-11ca0c70985b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RX4mWUu4rnpI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# copy the yandex click log from google drive\n",
        "!cp \"/gdrive/My Drive/YandexRelPredChallenge.txt\" ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lsO8vSi97QIA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Experiment parameters"
      ]
    },
    {
      "metadata": {
        "id": "4rmwQWDI7TJw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scale = 2  # the relevance scale (i.e. 2 = {0, 1} = binary, 3 = {0, 1, 2} = ternary, etc)\n",
        "cutoff = 3  # the cutoff rank\n",
        "theta = 0.15  # probability of not clicking on a relevant document\n",
        "thresholds = [(0.05, 0.1), \n",
        "              (0.1, 0.2), \n",
        "              (0.2, 0.3), \n",
        "              (0.3, 0.4), \n",
        "              (0.4, 0.5), \n",
        "              (0.5, 0.6), \n",
        "              (0.6, 0.7), \n",
        "              (0.7, 0.8), \n",
        "              (0.8, 0.9), \n",
        "              (0.9, 0.9500001)]  # the grouping thresholds\n",
        "p_overlapping_rel = 0.2  # the probability that a given pair of documents with the same relevance score will be overlapping\n",
        "p_overlapping_not_rel = 0.2\n",
        "overlapping_samples = 4  # the number of times we generate an ID for one pair (i.e. the number of potential overlapping combinations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1efDtgkpATLA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Run the experiment"
      ]
    },
    {
      "metadata": {
        "id": "_7C4rY6-AWfg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 1: Simulate Rankings of Relevance for *E* and *P*\n"
      ]
    },
    {
      "metadata": {
        "id": "yZHD7OR-W0HU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def simulate_pairs(scale, cutoff):\n",
        "    \"\"\"Generate pairs of rankings.\n",
        "\n",
        "    Args:\n",
        "        scale: the relevance scale (i.e. 2 = {0, 1} = binary, 3 = {0, 1, 2} = ternary, etc).\n",
        "        cutoff: the cutoff rank.\n",
        "    Returns:\n",
        "        list of pairs of rankings.\n",
        "    \"\"\"\n",
        "    rankings = np.array(list(itertools.product(range(scale), repeat=cutoff)))\n",
        "    pairs = np.array(list(itertools.product(rankings, repeat=2)))\n",
        "    return pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QSIh4EimAYOc",
        "colab_type": "code",
        "outputId": "7f2ad23f-a3b3-4446-f9fa-b8172a64cbb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "pairs = simulate_pairs(scale, cutoff)\n",
        "print(f'Number of unique pairs: {len(pairs)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique pairs: 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MHXCpTNZE_OI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2 - Calculate the *delta measure* and group the results"
      ]
    },
    {
      "metadata": {
        "id": "Vv6nxcAYetlU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Step 2a: Calculate the *delta measure*"
      ]
    },
    {
      "metadata": {
        "id": "fixGDTDXW47I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def err(ranking, theta):\n",
        "    \"\"\"Function that calculates ERR according to \"Expected Reciprocal Rank for Graded Relevance\" (Chapelle et al.)\n",
        "  \n",
        "    Args:\n",
        "        ranking: given ranking of documents with relevance scores\n",
        "        theta: parameter of ERR calculation. Function of relevance\n",
        "    Returns:\n",
        "        err: expected reciprocal rank for given ranking\n",
        "    \"\"\"\n",
        "    err = 0.0\n",
        "    p = 1.0\n",
        "    for i in range(len(ranking)):\n",
        "        r = np.abs(ranking[i] - theta)\n",
        "        err += p * r / (i + 1)\n",
        "        p *= 1 - r\n",
        "    return err\n",
        "\n",
        "\n",
        "def calculate_measures(pairs, theta):\n",
        "    \"\"\"Calculate the measure (ERR) for all ranking pairs.\n",
        "\n",
        "    Args:\n",
        "        pairs: the ranking pairs\n",
        "        theta: probability of not clicking on a relevant document\n",
        "    Returns:\n",
        "        list of tuples of (ranking pair, delta_err).\n",
        "    \"\"\"\n",
        "    pairs_measures = []\n",
        "    for pair in pairs:\n",
        "        err_e = err(pair[0], theta)\n",
        "        err_p = err(pair[1], theta)\n",
        "        if err_e > err_p:\n",
        "          delta_err = err_e - err_p\n",
        "          pairs_measures.append(np.array([pair, delta_err]))\n",
        "\n",
        "    return np.array(pairs_measures)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BdQIwBZkFKHA",
        "colab_type": "code",
        "outputId": "0f2b3d37-d6f6-4bd0-c227-9a81b44801e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "pairs_measures = calculate_measures(pairs, theta)\n",
        "print(f'Number of unique pairs for which E outperforms P (in terms of the measure): {len(pairs_measures)}')\n",
        "#print(f'Example (pair, measure) tuple: {list(random.choice(pairs_measures))}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique pairs for which E outperforms P (in terms of the measure): 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EM4QmZxHe79o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Step 2b: Group the results"
      ]
    },
    {
      "metadata": {
        "id": "UpK3dlrveNCg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def group_pairs_measures(pairs_measures, thresholds):\n",
        "    \"\"\"Group the ranking pairs on their measures (ERR).\n",
        "\n",
        "    Args:\n",
        "        pairs_measures: the (ranking pair, measure) tuples\n",
        "        thresholds: the predefined group thresholds\n",
        "    Returns:\n",
        "        list of groups containing their ranking pairs.\n",
        "    \"\"\"\n",
        "    grouping_dict = dict()\n",
        "    for i in range(len(pairs_measures)):\n",
        "        group = [j for j in range(len(thresholds)) if (pairs_measures[i][1] >= thresholds[j][0] and pairs_measures[i][1] < thresholds[j][1])]\n",
        "        if len(group) > 0:\n",
        "          grouping_dict[str(pairs_measures[i][0])] = group[0]\n",
        "        else:\n",
        "          grouping_dict[str(pairs_measures[i][0])] = None\n",
        "    return grouping_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "63Q3E582G920",
        "colab_type": "code",
        "outputId": "6915af0c-3235-4344-c780-8ee7ef7fda48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "grouping_dict = group_pairs_measures(pairs_measures, thresholds)\n",
        "print('Groups:')\n",
        "for i in range(len(thresholds)):\n",
        "    print(f'  {i+1: <2} ({thresholds[i][0]:.2f}, {thresholds[i][1]:.2f}): {list(grouping_dict.values()).count(i): <2} pairs')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Groups:\n",
            "  1  (0.05, 0.10): 2  pairs\n",
            "  2  (0.10, 0.20): 2  pairs\n",
            "  3  (0.20, 0.30): 2  pairs\n",
            "  4  (0.30, 0.40): 7  pairs\n",
            "  5  (0.40, 0.50): 4  pairs\n",
            "  6  (0.50, 0.60): 1  pairs\n",
            "  7  (0.60, 0.70): 4  pairs\n",
            "  8  (0.70, 0.80): 0  pairs\n",
            "  9  (0.80, 0.90): 0  pairs\n",
            "  10 (0.90, 0.95): 0  pairs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2tpOMaDHlvs4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Step 3: Implement Team-Draft Interleaving and Probabilistic Interleaving"
      ]
    },
    {
      "metadata": {
        "id": "HkP02SusmNj0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gen_ids(pair, probability_of_overlapping_rel, probability_of_overlapping_not_rel):\n",
        "    \"\"\" Function that generates IDs for documents in a pair of rankings.\n",
        "    \n",
        "    Args:\n",
        "        pair: pair of rankings (numpy array of dimensions (2,3)).\n",
        "        probability_of_overlapping_rel: probability that a pair of relevant documents will be overlapping (0<x<1)\n",
        "        probability_of_overlapping_not_rel: probability that a pair of not relevant documents with the same relevance will be\n",
        "        overlapping (0<x<1)\n",
        "    Returns:\n",
        "        ids: identifiers for pair of rankings (numpy array of dimensions (2,3), 0 for not overlapping, a>0 if overlapping and \n",
        "        relevant, a<0 if overlapping and not relevant)\n",
        "    Additional notes:\n",
        "        - we set probability_of_overlapping_rel = probability_of_overlapping_not_rel for simplification\n",
        "  \"\"\"\n",
        "    ids = np.zeros((2,3))\n",
        "    order_rel_e = np.random.permutation(np.where(pair[0,:] == 1)[0])\n",
        "    order_rel_p = np.random.permutation(np.where(pair[1,:] == 1)[0])\n",
        "    order_not_rel_e = np.random.permutation(np.where(pair[0,:] == 0)[0])\n",
        "    order_not_rel_p = np.random.permutation(np.where(pair[1,:] == 0)[0])    \n",
        "    overlappings_rel = np.min([np.min([sum(pair[0,:]), sum(pair[1,:])]), np.random.binomial(sum(pair[0,:]) * sum(pair[1,:]), probability_of_overlapping_rel)])\n",
        "    overlappings_not_rel = np.min([np.min([sum(pair[0,:]), sum(pair[1,:])]), np.random.binomial((3 - sum(pair[0,:])) * (3 - sum(pair[1,:])), probability_of_overlapping_not_rel)])\n",
        "    for i in range(overlappings_rel):\n",
        "        ids[0, order_rel_e[i]] = i + 1\n",
        "        ids[1, order_rel_p[i]] = (i + 1)     \n",
        "    for j in range(overlappings_not_rel):\n",
        "        ids[0, order_not_rel_e[j]] = - j - 1\n",
        "        ids[1, order_not_rel_p[j]] = (-j - 1)\n",
        "    total_overlappings = overlappings_not_rel + overlappings_rel\n",
        "    return ids, total_overlappings\n",
        "  \n",
        "  \n",
        "def softmax(vector):\n",
        "    \"\"\"Function calculates inverse softmax probabilities for a given vector.\n",
        "    \n",
        "    Args:\n",
        "        vector: vector of lenght n\n",
        "    Returns:\n",
        "        probabilities: softmax probabilities.\n",
        "    \"\"\"\n",
        "    probabilities = np.zeros((len(vector)))\n",
        "    sum_ = np.sum(np.exp(-vector))\n",
        "    for i in range(len(vector)):\n",
        "        probabilities[i] = np.exp(-vector[i]) / sum_\n",
        "    return probabilities\n",
        "  \n",
        "  \n",
        "def algorithm_orders():\n",
        "    \"\"\" Function that generates all possible orders of search engines for the interleaving process. \n",
        "    \n",
        "    Args:\n",
        "        none\n",
        "    Returns:\n",
        "        orders: all unique permutations of set (0,0,0,1,1,1)\n",
        "    \"\"\"\n",
        "    orders = list(itertools.permutations([0,0,0,1,1,1]))\n",
        "    \n",
        "    return list(set(orders))\n",
        "  \n",
        "def probabilistic_document_order(pair, ids):\n",
        "    \"\"\" Function that generates all possible orders in which a search engine will send its documents from given ranking, as well as \n",
        "        the probability of the given order being generated for probabilistic interleaving. Softmax over ranking is assumed.\n",
        "    \n",
        "    Args:\n",
        "        pair: pair of rankings produced by production and experimental algorithms\n",
        "        ids: identifiers determining if two documents are overlapping\n",
        "    Returns:\n",
        "        p_pair: all possible probabilistic orders produced by two algorithms\n",
        "        p_ids: identifiers that share indices with p_pair, used to generalize the interleaving function\n",
        "        probability_of_ranking_: probability of the pair of probabilistic orders being produced\n",
        "    \n",
        "    \"\"\"\n",
        "    p_pair = []\n",
        "    p_ids = []\n",
        "    p_prob = []\n",
        "    prob_order = list(itertools.permutations(range(3)))\n",
        "    prob_pairs = list(itertools.product(prob_order, repeat=2))\n",
        "    probability_of_ranking = []\n",
        "    for i in range(len(prob_order)):\n",
        "        prob__ = prob_order[i]\n",
        "        ranking_prob = 1\n",
        "        for j in range(len(prob_order[0])):\n",
        "            probs_ = softmax(np.asarray(prob__))\n",
        "            ranking_prob *= probs_[0]\n",
        "            prob__ = np.delete(prob__, 0)\n",
        "        probability_of_ranking.append(ranking_prob)\n",
        "    probability_of_ranking_ = np.asarray(list(itertools.product(probability_of_ranking, repeat=2)))\n",
        "    probability_of_ranking_ = probability_of_ranking_[:,0] * probability_of_ranking_[:,1]\n",
        "    for i in range(len(prob_pairs)):\n",
        "        pair_i = np.zeros((2,3))\n",
        "        ids_i = np.zeros((2,3))\n",
        "        prob_i = np.zeros((2))\n",
        "        for j in range(len(prob_pairs[0])):\n",
        "            prob_i[j] = 1\n",
        "            for k in range(len(prob_pairs[0][0])):\n",
        "                pair_i[j,k] = pair[j, prob_pairs[i][j][k]]\n",
        "                ids_i[j,k] = ids[j, prob_pairs[i][j][k]]\n",
        "        p_pair.append(pair_i)\n",
        "        p_ids.append(ids_i)\n",
        "        \n",
        "    return p_pair, p_ids, probability_of_ranking_\n",
        "  \n",
        "  \n",
        "def interleaving(pair, ids, order, total_overlappings):\n",
        "    \"\"\" Function performs the interleaving, given the:\n",
        "            - order of search engines (unique permutations of [0,0,0,1,1,1])\n",
        "            - order in which given search engine is sending its documents (probabilistic interleaving)\n",
        "            - total overlappings in the ranking\n",
        "        It is used for both team draft and probabilistic interleavings. \n",
        "            \n",
        "    Args:\n",
        "        pair: pair of rankings produced by two search engines. For probabilistic interleaving we interpret this input\n",
        "        as order in which the documents from given ranking are sent (numpy array of dimensions (2,3))\n",
        "        ids: identifiers of overlapping documents\n",
        "        order: order of search engines (unique permutations of [0,0,0,1,1,1])\n",
        "        total_overlappings: total count of overlapping cases, used to determine size of the interleaved list\n",
        "    Returns: \n",
        "        interleaved: a matrix of size (number of unique documents x 3). First column shows the \n",
        "        relevance of document on the list (0 - not relevant; 1 - relevant), second column shows which algorithm \n",
        "        sent the document (0 - experimental; 1 - production), third column shows if the document was overlapping\n",
        "        (0 - not overlapping; 1 - overlapping)\n",
        "    \n",
        "    \"\"\"\n",
        "    interleaved = np.zeros((6 - total_overlappings, 3))\n",
        "    queue_e = pair[0,:]\n",
        "    queue_p = pair[1,:]\n",
        "    ids_e = ids[0,:]\n",
        "    ids_p = ids[1,:]\n",
        "    for i in range(6 - total_overlappings):\n",
        "        if order[i] == 0 and len(queue_e) > 0:\n",
        "            interleaved[i, 0] = queue_e[0]\n",
        "            interleaved[i, 1] = 0\n",
        "            if ids_e[0] != 0:\n",
        "                queue_p = np.delete(queue_p, np.where(ids_p == ids_e[0])[0])\n",
        "                ids_p = np.delete(ids_p, np.where(ids_p == ids_e[0])[0])\n",
        "                interleaved[i, 2] = 1\n",
        "            queue_e = np.delete(queue_e, 0)\n",
        "            ids_e = np.delete(ids_e, 0)\n",
        "        if order[i] == 1 and len(queue_p) > 0:\n",
        "            interleaved[i, 0] = queue_p[0]\n",
        "            interleaved[i, 1] = 1\n",
        "            if ids_p[0] != 0:\n",
        "                queue_e = np.delete(queue_e, np.where(ids_e == ids_p[0])[0])\n",
        "                ids_e = np.delete(ids_e, np.where(ids_e == ids_p[0])[0])\n",
        "                interleaved[i, 2] = 1\n",
        "            queue_p = np.delete(queue_p, 0)\n",
        "            ids_p = np.delete(ids_p, 0)\n",
        "    return interleaved\n",
        "  \n",
        "        \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cuOEEKYzmVDg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 4: Simulate User Clicks\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xaltclfZneJk",
        "outputId": "13bca08c-a61f-414c-9dfa-be3b2a5b5077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "# Generating the dataset of queries and clicks\n",
        "\n",
        "queries = []\n",
        "clicks = []\n",
        "query = 'Q'\n",
        "click = 'C'\n",
        "\n",
        "with open('YandexRelPredChallenge.txt', 'r') as csvfile:\n",
        "  reader = csv.reader(csvfile, delimiter='\\t')\n",
        "  for row in reader:\n",
        "    if row[2] == query:\n",
        "      queries.append(row)\n",
        "    elif row[2] == click:\n",
        "      clicks.append(row)\n",
        "\n",
        "print(\"There are %i queries.\" % len(queries))\n",
        "print(\"The shortest query contains %i documents.\" % (len(min(queries, key = len)) - 5))\n",
        "print(\"The longest query contains %i documents.\" % (len(max(queries, key = len)) - 5))\n",
        "print(\"There are %i clicks.\" % len(clicks))\n",
        "\n",
        "# Optimizing the gamma and alpha parameters based on the Yandex query log \n",
        "# Using EM algorithm and formulas given by Markov  \n",
        "\n",
        "def obtain_click_parameters(clicks,queries):\n",
        "  #First, generate all the unique document-query pairs. Those are needed for keeping track of the alphas.\n",
        "  uniquepairs = []\n",
        "  for quer in queries:\n",
        "    urlids = quer[5:11]\n",
        "    for i in range(len(urlids)):\n",
        "      unique = quer[3] + ',' + urlids[i]\n",
        "      if unique not in [i[0] for i in uniquepairs]:\n",
        "        uniquepairs.append([unique,1])\n",
        "        count = count + 1\n",
        "      else:\n",
        "        indexx = uniquepairs.index([ind for ind in uniquepairs if unique in ind][0])\n",
        "        uniquepairs[indexx][1] = uniquepairs[indexx][1] + 1\n",
        "  #with open('uniquepairs.data', 'rb') as filehandle:  \n",
        "  #    uniquepairs = pickle.load(filehandle)\n",
        "  #Now, record all the clicked documents so that these checks don't have to be made inside the main loop.\n",
        "  clicked = []\n",
        "  clickid = []\n",
        "  temp = 0\n",
        "  tempclic = [0]\n",
        "  count = 1\n",
        "  for quer in queries:\n",
        "    if quer[0] not in clickid:\n",
        "      for clic in clicks:\n",
        "        if clic[0] == quer[0]:\n",
        "          if temp == int(clic[0]):\n",
        "            tempclic.append(clic[3])\n",
        "          else: \n",
        "            clicked.append(tempclic)\n",
        "            temp = temp + 1\n",
        "            tempclic = [temp]\n",
        "            clickid.append(clic[0])\n",
        "  clicked[0] = clicked[0][0:4]\n",
        "  clicked.append([13868,'411'])\n",
        "  clicked.append([13869])\n",
        "  #Initialize the gammas and the zeros\n",
        "  oldgammas = np.zeros(6)\n",
        "  oldalphas = []\n",
        "  gammas = np.zeros(6)\n",
        "  alphas = []\n",
        "  for i in range(len(uniquepairs)):\n",
        "    temp = uniquepairs[i][0:2]\n",
        "    temp.append(0)\n",
        "    alphas.append(temp)\n",
        "    oldalphas.append(temp)\n",
        "  alphas = np.asarray(alphas)\n",
        "  oldalphas = np.asarray(oldalphas)\n",
        "  #Iterate the EM algorithm until convergence.\n",
        "  goforward = True\n",
        "  difference = 0.01\n",
        "  iter = 0\n",
        "  while (goforward):\n",
        "    count = 0\n",
        "    for quer in queries:\n",
        "      id = quer[0]\n",
        "      urlid = quer[5:11]\n",
        "      qurlid = ''\n",
        "      j = 0\n",
        "      for url in urlid:\n",
        "        qurlid = quer[3] + ',' + url\n",
        "        alphaindex = np.where(alphas[:,0] == qurlid)\n",
        "        alphaindex = alphaindex[0]\n",
        "        if url in clicked[int(id)]:\n",
        "          gammas[j] = gammas[j] + 1\n",
        "          alphas[alphaindex,2] = float(alphas[alphaindex,2]) + 1\n",
        "        else:\n",
        "          gammas[j] = gammas[j] + oldgammas[j]*(1-float(oldalphas[alphaindex,2])) / (1 - oldgammas[j]*float(oldalphas[alphaindex,2]))  \n",
        "          alphas[alphaindex,2] = float(alphas[alphaindex,2]) + float(oldalphas[alphaindex,2])*(1-oldgammas[j]) / (1 - oldgammas[j]*float(oldalphas[alphaindex,2]))  \n",
        "        j = j + 1\n",
        "      count = count + 1\n",
        "      if (count % 5000) == 0:\n",
        "          print(count)\n",
        "    for j in range(len(alphas)):\n",
        "      alphas[j][2] = (1 + float(alphas[j][2])) / (int(alphas[j][1])+2)\n",
        "      oldalphas[j][2] = float(alphas[j][2])\n",
        "    for j in range(len(gammas)):\n",
        "      gammas[j] = (1+gammas[j])/(len(queries)+2)\n",
        "      if (abs(gammas[j] - oldgammas[j]) < difference):\n",
        "        goforward = False\n",
        "      oldgammas[j] = gammas[j]\n",
        "    iter = iter + 1\n",
        "    print('iteration: %i' % iter)\n",
        "    print(gammas)\n",
        "  return gammas, alphas\n",
        "  \n",
        "#gammas, alphas = obtain_click_parameters(clicks,queries)\n",
        "\n",
        "# after 10 iterations, these gammas were obtained\n",
        "gammas = [0.50022533, 0.29569979, 0.22755148, 0.18252781, 0.14754686, 0.1253613]\n",
        "\n",
        "# the learned alphas were discarded and replaced with the following value\n",
        "alpha = 0.8"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 42652 queries.\n",
            "The shortest query contains 10 documents.\n",
            "The longest query contains 10 documents.\n",
            "There are 57348 clicks.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5X2dtHrPniOZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Method that simulates clicking on a document having read it\n",
        "def tosscoin(relev, alpha, ind):\n",
        "  cointwo = random.random()\n",
        "  if cointwo < (relev*alpha + (1-relev)*(1-alpha)):\n",
        "    return ind, True\n",
        "  else:\n",
        "    return -1, False\n",
        "\n",
        "#Method that simulates a position-based click model\n",
        "def sim_click(interleaved,gammas,alpha):\n",
        "  clickInd = -1    \n",
        "  while (clickInd==-1):\n",
        "    coin = random.random()\n",
        "    for i in range(len(interleaved)):\n",
        "      if coin < gammas[i]:\n",
        "        clickInd, stop = tosscoin(interleaved[i,0],alpha,i)\n",
        "        if stop:\n",
        "          return clickInd\n",
        "  return clickInd\n",
        "\n",
        "#Method that simulates a random click model    \n",
        "def sim_random_click(n):\n",
        "  return random.randint(0,(n-1))\n",
        "\n",
        "#Method that repeats the click simulation n times for a given interleaved list\n",
        "#Runs it for either PBM or RND model, depending on boolean 'random'\n",
        "def sim_click_model(interleaved, gammas, alpha, n, random = False):\n",
        "  wins = np.zeros(n)\n",
        "  for i in range(n):\n",
        "    if (not random):\n",
        "      indd = sim_click(interleaved,gammas,alpha)\n",
        "      wins[i] = int(interleaved[indd,1])\n",
        "    else: \n",
        "      indd = sim_random_click(len(interleaved))\n",
        "      wins[i] = int(interleaved[indd,1])\n",
        "  win = sum(wins) / n\n",
        "  if win > 0.5:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "12WiCNf6mglA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 5: Simulate Interleaving Experiment\n"
      ]
    },
    {
      "metadata": {
        "id": "lipxFVuLc4c0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Step 5a: Team-Draft Interleaving"
      ]
    },
    {
      "metadata": {
        "id": "gdcsnym9mmgs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def team_draft_interleaving(pairs, p_overlapping_rel, p_overlapping_not_rel, overlapping_samples):\n",
        "  \"\"\" \n",
        "  Function performs all iterations of team draft interleaving.    \n",
        "  Args:\n",
        "    pairs: output of the function simulate_pairs\n",
        "    p_overlapping_rel\n",
        "    p_overlapping_not_rel\n",
        "    overlapping_samples: number of times we sample potential overlaps in documents for each sample\n",
        "  Returns:\n",
        "    proportions: data structure that notes (delta_ERR, p1_positional, p1_random) for each sampled pair x overlapping_samples)           \n",
        "  \"\"\"\n",
        "  proportions = []\n",
        "  orders = algorithm_orders()\n",
        "  n = 100  # the number of simulations\n",
        "  for i in range(len(pairs)): # we iterate over every possible pair\n",
        "    pair_i = np.asarray(pairs[i])\n",
        "    delta_ERR = err(pair_i[0,:], theta) - err(pair_i[1,:], theta) # calculate delta_err\n",
        "    if delta_ERR >= 0.05 and delta_ERR <= 0.95:\n",
        "      for k in range(overlapping_samples): # if delta_err falls into desired bracket, we sample different combinations of overlapping in documents\n",
        "        ids_i, overlappings_i = gen_ids(pair_i, p_overlapping_rel, p_overlapping_not_rel)\n",
        "        result = np.zeros((3))\n",
        "        PBM_wins = []\n",
        "        RND_wins = [] \n",
        "        for j in range(len(orders)): # we iterate over every possible team draft order\n",
        "          interleaving_ = interleaving(pair_i, ids_i, np.asarray(orders[j]), overlappings_i) # we calculate interleaving for every combination of pair, order and overlapping\n",
        "          PBM_win = sim_click_model(interleaving_, gammas, alpha, n)  # we simulate clicks for positional click model\n",
        "          RND_win = sim_click_model(interleaving_, gammas, alpha, n, random=True) # and random click model\n",
        "          PBM_wins.append('E' if PBM_win == 0 else 'P')\n",
        "          RND_wins.append('E' if RND_win == 0 else 'P')\n",
        "        result[0] = delta_ERR\n",
        "        result[1] = PBM_wins.count('E') / len(PBM_wins)\n",
        "        result[2] = RND_wins.count('E') / len(RND_wins)\n",
        "        proportions.append(result)\n",
        "  return np.asarray(proportions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vQDpNPduJUBn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 5b: Probabilistic Interleaving**"
      ]
    },
    {
      "metadata": {
        "id": "rhusEpuyjj-m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def probabilistic_interleaving(pairs, p_overlapping_rel, p_overlapping_not_rel, overlapping_samples):\n",
        "    \"\"\" Function performs all iterations of probabilistic interleaving.\n",
        "\n",
        "        Args:\n",
        "            pairs: output of the function simulate_pairs\n",
        "            p_overlapping_rel\n",
        "            p_overlapping_not_rel\n",
        "            overlapping_samples: number of times we sample potential overlaps in documents for each sample\n",
        "        Returns:\n",
        "            proportions: data structure that notes (delta_ERR, p1_positional, p1_random) for each sampled pair x overlapping_samples)\n",
        "\n",
        "    \"\"\"\n",
        "    proportions = []\n",
        "    orders = algorithm_orders()\n",
        "    n = 100  # the number of simulations\n",
        "    for i in range(len(pairs)): # we iterate over every possible pair\n",
        "        pair_i = np.asarray(pairs[i])\n",
        "        delta_ERR_ = err(pair_i[0,:], theta) - err(pair_i[1,:], theta) # calculate delta_err\n",
        "        if delta_ERR_ >= 0.05 and delta_ERR_ <= 0.95:\n",
        "            for m in range(overlapping_samples): # if delta_err falls into desired bracket, we sample different combinations of overlapping in documents\n",
        "                ids_i, overlappings_i = gen_ids(pairs[i], p_overlapping_rel, p_overlapping_not_rel)\n",
        "                result = np.zeros((3))\n",
        "                PBM_wins = []\n",
        "                RND_wins = []\n",
        "                total = 0\n",
        "                prob_pairs, prob_ids, prob_of_ranking = probabilistic_document_order(pair_i, ids_i)\n",
        "                for j in range(len(orders)): # we iterate over every possible team draft order\n",
        "                    for k in range(len(prob_pairs)): # we iterate over every order in which algorithms can send their documents\n",
        "                        interleaving_ = interleaving(pair_i, ids_i, np.asarray(orders[j]), overlappings_i)\n",
        "                        PBM_win = sim_click_model(interleaving_, gammas, alpha, n) # we simulate clicks\n",
        "                        RND_win = sim_click_model(interleaving_, gammas, alpha, n, random=True)\n",
        "                        PBM_wins.append(prob_of_ranking[k] if PBM_win == 0 else 0) # since we analyse 1 of every combination of probabilstic interleaving, we weight win by probability of that interleaving occuring\n",
        "                        RND_wins.append(prob_of_ranking[k] if RND_win == 0 else 0)\n",
        "                        total += prob_of_ranking[k]\n",
        "                result[0] = delta_ERR_\n",
        "                result[1] = sum(PBM_wins) / total\n",
        "                result[2] = sum(RND_wins) / total\n",
        "                proportions.append(result)\n",
        "    return np.asarray(proportions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fV2epyC29FPo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "team_draft_results = team_draft_interleaving(pairs, p_overlapping_rel, p_overlapping_not_rel, overlapping_samples)\n",
        "probabilistic_results = probabilistic_interleaving(pairs, p_overlapping_rel, p_overlapping_not_rel, overlapping_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9o_GvfhCmnwY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 6: Compute Sample Size"
      ]
    },
    {
      "metadata": {
        "id": "wpHn7Spnmtfk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_sided_proportion_test(p1, p0=0.5, alpha=0.05, beta=0.10):\n",
        "    \"\"\"Calculate the sample size using a proportion test for the 1-sided case.\n",
        "\n",
        "    Args:\n",
        "        p1: the proportion of times E wins over P\n",
        "        p0: baseline proportion to compare p1 with\n",
        "        alpha: probability of false positive\n",
        "        beta: probability of false negative\n",
        "    Returns:\n",
        "        the sample size required\n",
        "    \"\"\"\n",
        "    if p1 - p0 < 0.0000001:\n",
        "        return np.inf\n",
        "    \n",
        "    z_alpha = norm.ppf(1.0 - alpha)\n",
        "    z_beta = norm.ppf(1.0 - beta)\n",
        "    \n",
        "    n = np.int_(np.ceil(p0 * (1 - p0) * ((z_alpha + z_beta * np.sqrt((p1 * (1 - p1)) / (p0 * (1 - p0)))) / (p1 - p0)) ** 2))\n",
        "\n",
        "    return n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ue3lh2hubYmM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Step 6a: Team-Draft Interleaving"
      ]
    },
    {
      "metadata": {
        "id": "dcU8E5rzbUOg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get the proportions for the group\n",
        "team_draft_delta_ERRs = team_draft_results[:, 0]\n",
        "team_draft_PBM_proportions = team_draft_results[:, 1]\n",
        "team_draft_RND_proportions = team_draft_results[:, 2]\n",
        "\n",
        "team_draft_PBM_sample_sizes = []\n",
        "team_draft_RND_sample_sizes = []\n",
        "\n",
        "for i in range(len(team_draft_PBM_proportions)):\n",
        "    team_draft_PBM_sample_sizes.append(one_sided_proportion_test(team_draft_PBM_proportions[i]))\n",
        "    team_draft_RND_sample_sizes.append(one_sided_proportion_test(team_draft_RND_proportions[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R0D-iZ7KcAg4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Step 6b: Probabilistic Interleaving"
      ]
    },
    {
      "metadata": {
        "id": "0wkox-Q-cFvQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get the proportions for the group\n",
        "probabilistic_delta_ERRs = probabilistic_results[:, 0]\n",
        "probabilistic_PBM_proportions = probabilistic_results[:, 1]\n",
        "probabilistic_RND_proportions = probabilistic_results[:, 2]\n",
        "\n",
        "probabilistic_PBM_sample_sizes = []\n",
        "probabilistic_RND_sample_sizes = []\n",
        "\n",
        "for i in range(len(probabilistic_PBM_proportions)):\n",
        "    probabilistic_PBM_sample_sizes.append(one_sided_proportion_test(probabilistic_PBM_proportions[i]))\n",
        "    probabilistic_RND_sample_sizes.append(one_sided_proportion_test(probabilistic_RND_proportions[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GIxuhxHDZCdV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Step 6c: Group the results"
      ]
    },
    {
      "metadata": {
        "id": "CeHvKjZUZFex",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "team_draft_PBM_sample_sizes_grouped = [[] for treshold in thresholds]\n",
        "team_draft_RND_sample_sizes_grouped = [[] for treshold in thresholds]\n",
        "\n",
        "for i in range(len(team_draft_PBM_sample_sizes)):\n",
        "    group = [j for j in range(len(thresholds)) if (team_draft_delta_ERRs[i] >= thresholds[j][0] and team_draft_delta_ERRs[i] < thresholds[j][1])]\n",
        "    if len(group) > 0:\n",
        "        team_draft_PBM_sample_sizes_grouped[group[0]].append(team_draft_PBM_sample_sizes[i])\n",
        "        team_draft_RND_sample_sizes_grouped[group[0]].append(team_draft_RND_sample_sizes[i])\n",
        "        \n",
        "probabilistic_PBM_sample_sizes_grouped = [[] for treshold in thresholds]\n",
        "probabilistic_RND_sample_sizes_grouped = [[] for treshold in thresholds]\n",
        "\n",
        "for i in range(len(probabilistic_PBM_sample_sizes)):\n",
        "    group = [j for j in range(len(thresholds)) if (probabilistic_delta_ERRs[i] >= thresholds[j][0] and probabilistic_delta_ERRs[i] < thresholds[j][1])]\n",
        "    if len(group) > 0:\n",
        "        probabilistic_PBM_sample_sizes_grouped[group[0]].append(probabilistic_PBM_sample_sizes[i])\n",
        "        probabilistic_RND_sample_sizes_grouped[group[0]].append(probabilistic_RND_sample_sizes[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NGLjzFLBmyNI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 7: Analysis"
      ]
    },
    {
      "metadata": {
        "id": "-EH6_U_ZdBCk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Step 7a: Team-Draft Interleaving"
      ]
    },
    {
      "metadata": {
        "id": "J3_jW0Urmx0I",
        "colab_type": "code",
        "outputId": "27fa9e36-c273-48e1-f171-379eb5b20985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "print('Position Based Model, Team-Draft interleaving')\n",
        "print('ΔERR                 Min       Median    Max       ')\n",
        "for i in range(len(thresholds)): # loop for each group/bin\n",
        "    if len(team_draft_PBM_sample_sizes_grouped[i]) > 0:\n",
        "        min_ = min(team_draft_PBM_sample_sizes_grouped[i])\n",
        "        median_ = np.int_(np.median(team_draft_PBM_sample_sizes_grouped[i]))\n",
        "        if median_ < 0:\n",
        "            median_ = np.inf\n",
        "        max_ = max(team_draft_PBM_sample_sizes_grouped[i])\n",
        "    \n",
        "        print(f'[{thresholds[i][0]:.2f}, {thresholds[i][1]:.2f}) (n={len(team_draft_RND_sample_sizes_grouped[i]): <2}): {min_: <9} {median_: <9} {max_: <9}')\n",
        "\n",
        "print()\n",
        "print('Random Click Model, Team-Draft interleaving')\n",
        "print('ΔERR                 Min       Median    Max       ')\n",
        "for i in range(len(thresholds)): # loop for each group/bin\n",
        "    if len(team_draft_RND_sample_sizes_grouped[i]) > 0:\n",
        "        min_ = min(team_draft_RND_sample_sizes_grouped[i])\n",
        "        median_ = np.int_(np.median(team_draft_RND_sample_sizes_grouped[i]))\n",
        "        if median_ < 0:\n",
        "            median_ = np.inf\n",
        "        max_ = max(team_draft_RND_sample_sizes_grouped[i])\n",
        "    \n",
        "        print(f'[{thresholds[i][0]:.2f}, {thresholds[i][1]:.2f}) (n={len(team_draft_RND_sample_sizes_grouped[i]): <2}): {min_: <9} {median_: <9} {max_: <9}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Position Based Model, Team-Draft interleaving\n",
            "ΔERR                 Min       Median    Max       \n",
            "[0.05, 0.10) (n=8 ): 92        inf       inf      \n",
            "[0.10, 0.20) (n=8 ): 50        92        211      \n",
            "[0.20, 0.30) (n=8 ): 20        50        92       \n",
            "[0.30, 0.40) (n=28): 20        20        31       \n",
            "[0.40, 0.50) (n=16): 10        20        20       \n",
            "[0.50, 0.60) (n=4 ): 20        20        20       \n",
            "[0.60, 0.70) (n=16): 10        14        20       \n",
            "\n",
            "Random Click Model, Team-Draft interleaving\n",
            "ΔERR                 Min       Median    Max       \n",
            "[0.05, 0.10) (n=8 ): 20        inf       inf      \n",
            "[0.10, 0.20) (n=8 ): 31        532       inf      \n",
            "[0.20, 0.30) (n=8 ): 92        532       inf      \n",
            "[0.30, 0.40) (n=28): 6         92        inf      \n",
            "[0.40, 0.50) (n=16): 14        211       inf      \n",
            "[0.50, 0.60) (n=4 ): 6         inf       inf      \n",
            "[0.60, 0.70) (n=16): 31        532       inf      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m-7GYehbfqCM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Step 7b: Probabilistic Interleaving"
      ]
    },
    {
      "metadata": {
        "id": "TnJrr2D9fJWA",
        "colab_type": "code",
        "outputId": "19adfce9-36a0-467c-d834-323a70e675b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "print('Position Based Model, Probabilistic interleaving')\n",
        "print('ΔERR                 Min       Median    Max       ')\n",
        "for i in range(len(thresholds)): # loop for each group/bin\n",
        "    if len(probabilistic_PBM_sample_sizes_grouped[i]) > 0:\n",
        "        min_ = min(probabilistic_PBM_sample_sizes_grouped[i])\n",
        "        median_ = np.int_(np.median(probabilistic_PBM_sample_sizes_grouped[i]))\n",
        "        if median_ < 0:\n",
        "            median_ = np.inf\n",
        "        max_ = max(probabilistic_PBM_sample_sizes_grouped[i])\n",
        "    \n",
        "        print(f'[{thresholds[i][0]:.2f}, {thresholds[i][1]:.2f}) (n={len(probabilistic_PBM_sample_sizes_grouped[i]): <2}): {min_: <9} {median_: <9} {max_: <9}')\n",
        "\n",
        "print()\n",
        "print('Random Click Model, Probabilistic interleaving')\n",
        "print('ΔERR                 Min       Median    Max       ')\n",
        "for i in range(len(thresholds)): # loop for each group/bin\n",
        "    if len(probabilistic_RND_sample_sizes_grouped[i]) > 0:\n",
        "        min_ = min(probabilistic_RND_sample_sizes_grouped[i])\n",
        "        median_ = np.int_(np.median(probabilistic_RND_sample_sizes_grouped[i]))\n",
        "        if median_ < 0:\n",
        "            median_ = np.inf\n",
        "        max_ = max(probabilistic_RND_sample_sizes_grouped[i])\n",
        "    \n",
        "        print(f'[{thresholds[i][0]:.2f}, {thresholds[i][1]:.2f}) (n={len(probabilistic_RND_sample_sizes_grouped[i]): <2}): {min_: <9} {median_: <9} {max_: <9}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Position Based Model, Probabilistic interleaving\n",
            "ΔERR                 Min       Median    Max       \n",
            "[0.05, 0.10) (n=8 ): 86        inf       inf      \n",
            "[0.10, 0.20) (n=8 ): 54        99        186      \n",
            "[0.20, 0.30) (n=8 ): 32        44        59       \n",
            "[0.30, 0.40) (n=28): 20        20        23       \n",
            "[0.40, 0.50) (n=16): 13        17        21       \n",
            "[0.50, 0.60) (n=4 ): 13        15        17       \n",
            "[0.60, 0.70) (n=16): 12        15        17       \n",
            "\n",
            "Random Click Model, Probabilistic interleaving\n",
            "ΔERR                 Min       Median    Max       \n",
            "[0.05, 0.10) (n=8 ): 15        5389      inf      \n",
            "[0.10, 0.20) (n=8 ): 53        1095      inf      \n",
            "[0.20, 0.30) (n=8 ): 199       839       2330743  \n",
            "[0.30, 0.40) (n=28): 15        700       inf      \n",
            "[0.40, 0.50) (n=16): 7         604       inf      \n",
            "[0.50, 0.60) (n=4 ): 7         153       112717   \n",
            "[0.60, 0.70) (n=16): 156       886       inf      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "McEDdrEYFXFY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Step 7c: Results and Conclusions"
      ]
    },
    {
      "metadata": {
        "id": "u_hGcy66o9oN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Correlation between ERR (offline metric) and proportions of wins (online metric)"
      ]
    },
    {
      "metadata": {
        "id": "YlLCt1NAnaB0",
        "colab_type": "code",
        "outputId": "5e5fda53-6309-4a82-c98f-42267ba4698c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "slope, intercept, r_value, p_value, std_err = stats.linregress(team_draft_delta_ERRs, team_draft_PBM_proportions)\n",
        "print(f\"For Team-Draft interleaving, with the PBM click model, there is a {'significant' if p_value < 0.05 else 'not significant'}, {'positive' if slope > 0 else 'negative'} relationship between ΔERR and the proportion of wins of E over P with coefficient={slope:.4f} and p = {p_value}.\")\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(team_draft_delta_ERRs, team_draft_RND_proportions)\n",
        "print(f\"For Team-Draft interleaving, with the RND click model, there is a {'significant' if p_value < 0.05 else 'not significant'}, {'positive' if slope > 0 else 'negative'} relationship between ΔERR and the proportion of wins of E over P with coefficient={slope:.4f} and p = {p_value}.\")\n",
        "\n",
        "print()\n",
        "\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(probabilistic_delta_ERRs, probabilistic_PBM_proportions)\n",
        "print(f\"For Probabilistic interleaving, with the PBM click model, there is a {'significant' if p_value < 0.05 else 'not significant'}, {'positive' if slope > 0 else 'negative'} relationship between ΔERR and the proportion of wins of E over P with coefficient={slope:.4f} and p = {p_value}.\")\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(probabilistic_delta_ERRs, probabilistic_RND_proportions)\n",
        "print(f\"For Probabilistic interleaving, with the RND click model, there is a {'significant' if p_value < 0.05 else 'not significant'}, {'positive' if slope > 0 else 'negative'} relationship between ΔERR and the proportion of wins of E over P with coefficient={slope:.4f} and p = {p_value}.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Team-Draft interleaving, with the PBM click model, there is a significant, positive relationship between ΔERR and the proportion of wins of E over P with coefficient=0.4629 and p = 5.2169188679920105e-24.\n",
            "For Team-Draft interleaving, with the RND click model, there is a not significant, positive relationship between ΔERR and the proportion of wins of E over P with coefficient=0.0175 and p = 0.8523434258164561.\n",
            "\n",
            "For Probabilistic interleaving, with the PBM click model, there is a significant, positive relationship between ΔERR and the proportion of wins of E over P with coefficient=0.4547 and p = 2.0313011658449783e-27.\n",
            "For Probabilistic interleaving, with the RND click model, there is a not significant, positive relationship between ΔERR and the proportion of wins of E over P with coefficient=0.0112 and p = 0.8737685640587385.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VTAP0qunFwc0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When looking at the relationship between the *ΔERR* (our offline measure) and the proportion of wins of algorithm E over P *p1* (our online measure), we observe a significant (at the 95% confidence interval), positive relationship for the PBM click model (and a non-significant, negative relationship for the Random click model).\n",
        "\n",
        "This would suggest that our offline measure does indeed inform our online measure!"
      ]
    },
    {
      "metadata": {
        "id": "mTmzJtRynHlg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### (Non-)Significant differences between the PBM click model and the Random click model"
      ]
    },
    {
      "metadata": {
        "id": "K_SjGD9E8hb0",
        "colab_type": "code",
        "outputId": "236de648-4274-448c-a77d-6448b5a65e14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# discard all entries where the sample size is infinite\n",
        "PBM_sample_sizes = team_draft_PBM_sample_sizes + probabilistic_PBM_sample_sizes\n",
        "RND_sample_sizes = team_draft_RND_sample_sizes + probabilistic_RND_sample_sizes\n",
        "\n",
        "new_PBM_sample_sizes = []\n",
        "new_RND_sample_sizes = []\n",
        "\n",
        "for i in range(len(PBM_sample_sizes)):\n",
        "   if PBM_sample_sizes[i] != np.inf and RND_sample_sizes[i] != np.inf:\n",
        "        new_PBM_sample_sizes.append(PBM_sample_sizes[i])\n",
        "        new_RND_sample_sizes.append(RND_sample_sizes[i])\n",
        "\n",
        "# compute the t-test\n",
        "statistic, p_value = ttest_ind(new_PBM_sample_sizes, new_RND_sample_sizes, equal_var=False)\n",
        "\n",
        "print(f\"The difference in sample sizes between the PBM click modeland the\\nRandom click model is {'significant' if p_value / 2 < 0.05 else 'not significant'} (1-sided t-test, p: {p_value / 2:.4f})\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The difference in sample sizes between the PBM click modeland the\n",
            "Random click model is significant (1-sided t-test, p: 0.0374)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "64062GSPSjFA",
        "colab_type": "code",
        "outputId": "d80ef0d2-d5ec-4f15-931d-f6cf63e0bb50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "PBM_proportions = team_draft_PBM_proportions + probabilistic_PBM_proportions\n",
        "RND_proportions = team_draft_RND_proportions + probabilistic_RND_proportions\n",
        "\n",
        "# compute the t-test for the proportion of wins\n",
        "statistic, p_value = ttest_ind(PBM_proportions, RND_proportions, equal_var=False)\n",
        "\n",
        "print(f\"The difference in proportion of wins p1 between the PBM click model and\\nthe Random click model is {'significant' if p_value / 2 < 0.05 else 'not significant'} (1-sided t-test, p: {p_value / 2})\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The difference in proportion of wins p1 between the PBM click model and\n",
            "the Random click model is significant (1-sided t-test, p: 7.897870634839043e-24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FNHSo8HeH10w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When looking at the results of our interleaving experiments, one immediately notices the differences between the PBM click model and the Random click model, for both Team-Draft and Probabilistic interleaving, in terms of the computed sample sizes.\n",
        "\n",
        "As expected, with the Random click model, many more impressions (sometimes infinitely many if p1 ~ p0) are needed for our interleaving experiments, when compared to the PBM click model. This difference is significant (at the 95% confidence interval).\n",
        "\n",
        "This is because, essentially, the Random click model ignores any differences in rank (and thus differences in relevance) between the documents presented in the interleaving. As such, the values for p1 will be closer to (or even below) 0.5, when compared to the PBM click model, resulting in larger sample sizes required."
      ]
    },
    {
      "metadata": {
        "id": "RvRoPa_BFTX4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### (Non-)Significant differences between Team-Draft interleaving and Probabilistic interleaving"
      ]
    },
    {
      "metadata": {
        "id": "ofSWKbHU7DfU",
        "colab_type": "code",
        "outputId": "393b1286-6219-4ec8-9ce6-5d61cfbfd926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "# discard all entries where the sample size is infinite\n",
        "new_team_draft_PBM_sample_sizes = []\n",
        "new_probabilistic_PBM_sample_sizes = []\n",
        "\n",
        "for i in range(len(team_draft_PBM_sample_sizes)):\n",
        "   if team_draft_PBM_sample_sizes[i] != np.inf and probabilistic_PBM_sample_sizes != np.inf:\n",
        "        new_team_draft_PBM_sample_sizes.append(team_draft_PBM_sample_sizes[i])\n",
        "        new_probabilistic_PBM_sample_sizes.append(probabilistic_PBM_sample_sizes[i])\n",
        "\n",
        "# compute the t-test for the sample sizes\n",
        "statistic, p_value = ttest_ind(new_team_draft_PBM_sample_sizes, new_probabilistic_PBM_sample_sizes, equal_var=False)\n",
        "\n",
        "print(f\"The difference in sample sizes between Team-Draft interleaving and\\nProbabilistic interleaving for the PBM click model\\nis {'significant' if p_value / 2 < 0.05 else 'not significant'} (1-sided t-test, p: {p_value / 2:.4f})\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The difference in sample sizes between Team-Draft interleaving and\n",
            "Probabilistic interleaving for the PBM click model\n",
            "is not significant (1-sided t-test, p: 0.2068)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wJ1RBgTUSAgg",
        "colab_type": "code",
        "outputId": "1edac4c9-c87a-4115-ba96-dbfbf62ce058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "# compute the t-test for the proportion of wins\n",
        "statistic, p_value = ttest_ind(team_draft_PBM_proportions, probabilistic_PBM_proportions, equal_var=False)\n",
        "\n",
        "print(f\"The difference in proportion of wins p1 between Team-Draft\\ninterleaving and Probabilistic interleaving for the PBM\\nclick model is {'significant' if p_value / 2 < 0.05 else 'not significant'} (1-sided t-test, p: {p_value / 2:.4f})\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The difference in proportion of wins p1 between Team-Draft\n",
            "interleaving and Probabilistic interleaving for the PBM\n",
            "click model is not significant (1-sided t-test, p: 0.3260)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QptcB28_qePA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Moreover, while Probabilistic interleaving does result in lower sample sizes for most bins, the differences are rather small and non-significant (at the 95% confidence interval). They definitely don't differ by a factor of 2^3=8 (where Probabilistic would need 8 times fewer samples than Team-Draft) as put forward in our design proposal.\n"
      ]
    },
    {
      "metadata": {
        "id": "b9XmbT8mqWDk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Step 7d: Limitations and Possible Improvements"
      ]
    },
    {
      "metadata": {
        "id": "EeKm9V02nRTY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Despite the results that confirmed some of the expectations we have set out in the theoretical paper, there are still some limitations and room for possible improvement. \n",
        "\n",
        "Most importantly, there are several restrictions that were imposed by the design of the experiment. Due to the coarse relevance grading scale and low cut-off rank, there were fewer combinations of ranking pairs and, hence, fewer possible ΔERR results and possible intereleaved lists. This led to a small number of samples per ΔERR bin, and improving this aspect might make the findings of this experiment more stable. Also as a result of this limitation, we observed a weaker difference between team-draft and probabilistic interleaving methods. \n",
        "\n",
        "There is also room for improvement in terms of broading the diversity of metrics and algorithms employed in this experiment. Firstly, the number of metrics to evaluate a ranking could be enlarged: next to Expected Reciprocal Rank, Discounted Cumulative Gain, Rank-Based Precision or Mean Average Precision could be included. Secondly, more interleaving methods could be evaluated: Balanced, which is more primitive than Team-Draft and Probabilistic methods, and Optimized, which is reported to improve on the Probabilistic approach. \n",
        "\n",
        "Perhaps the most important improvement needed for this experiment is the inclusion of more sophisticated click models that accurately mimic user behavior. Since in our experiment, attractiveness of the document was substitued by the crude relevance score, other algorithms might capture these differences. This might prove to be challenging because it would require running the experiment on more detailed datasets rather than artificially simulated rankings produced for a single query, as is the case in our paper. \n",
        "\n",
        "Nevertheless, while inclusion of the above mentioned improvements might change the outcomes of the experiment, we believe that we confirmed our initial hypothesis of negative correlation between delta_ERR / predicted sample size and presented a case for predicting sample sizes needed in online experiments. "
      ]
    },
    {
      "metadata": {
        "id": "aF-Ua8Xxv-6p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### References"
      ]
    },
    {
      "metadata": {
        "id": "L3txVaG-xBd6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Azarbonyad, H., & Kanoulas, E. (2016, September). Power Analysis for Interleaving Experiments by means of Offline Evaluation. In Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval (pp. 87-90). ACM.\n",
        "\n",
        "Chapelle, O., Metlzer, D., Zhang, Y., & Grinspan, P. (2009, November). Expected reciprocal rank for graded relevance. In Proceedings of the 18th ACM conference on Information and knowledge management (pp. 621-630). ACM.\n",
        "\n",
        "Chuklin, A., Markov, I., & Rijke, M. D. (2015). Click models for web search. Synthesis Lectures on Information Concepts, Retrieval, and Services, 7(3), 1-115.\n",
        "\n",
        "Dupret, G. (2011, October). Discounted cumulative gain and user decision models. In International Symposium on String Processing and Information Retrieval (pp. 2-13). Springer, Berlin, Heidelberg.\n",
        "\n",
        "Hofmann, K., Whiteson, S., & De Rijke, M. (2011, October). A probabilistic method for inferring preferences from clicks. In Proceedings of the 20th ACM international conference on Information and knowledge management (pp. 249-258). ACM.\n",
        "\n",
        "Radlinski, F., & Craswell, N. (2013, February). Optimized interleaving for online retrieval evaluation. In Proceedings of the sixth ACM international conference on Web search and data mining (pp. 245-254). ACM."
      ]
    }
  ]
}